{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rime-am/projet_bigdata/blob/main/analyse_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EPSwfyeVp7IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse des sentiments"
      ],
      "metadata": {
        "id": "MrPXXkwhuz6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On utilise comme données des avis sur des livres.\n",
        "\n"
      ],
      "metadata": {
        "id": "R5CQy0zDuz6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#on crée notre session Spark\n",
        "spark = SparkSession.builder.master(\"local[1]\").appName(\"SparkByExamples.com\").getOrCreate()\n",
        "spark.conf.set('spark.sql.shuffle.partitions', '100')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huvugIqEuz6d",
        "outputId": "2fe5081d-3738-43dd-98a7-a337c19192a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notre dataset\n",
        "Nos données nous viennent  du site suivant (http://jmcauley.ucsd.edu/data/amazon/). Le fichier contient originalement 982,619 avis. Nous avons utilsé un fichier plus léger (50000 avis).\n"
      ],
      "metadata": {
        "id": "ZFXhMTWquz6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# notre fichier de données\n",
        "kindle_json = spark.read.json('Kindle_Stode_51.json')"
      ],
      "metadata": {
        "id": "SPobM_WYuz6n"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "kindle_json.show(3)"
      ],
      "metadata": {
        "id": "RVr0WlPvuz6p",
        "outputId": "e8956d24-f125-40b5-edd5-54c6f5e234d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\n",
            "|      asin|helpful|overall|          reviewText|reviewTime|    reviewerID|reviewerName|           summary|unixReviewTime|\n",
            "+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\n",
            "|B000F83SZQ| [0, 0]|    5.0|I enjoy vintage b...|05 5, 2014|A1F6404F1VG29J|  Avidreader|Nice vintage story|    1399248000|\n",
            "|B000F83SZQ| [2, 2]|    4.0|This book is a re...|01 6, 2014| AN0N05A9LIJEQ|    critters|      Different...|    1388966400|\n",
            "|B000F83SZQ| [2, 2]|    4.0|This was a fairly...|04 4, 2014| A795DMNCJILA6|         dot|             Oldie|    1396569600|\n",
            "+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label pour les setiments\n",
        "\n",
        "Les livres avec des évaluations de 1, 2, ou 3 sont considérés comme des évaluations négatives (label=1), et les livres avec des évaluations de 4 et de 5 sont considérés commme des évaluations positives (label=0)."
      ],
      "metadata": {
        "id": "FFDILjoBuz6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kindle_json.createOrReplaceTempView('kindle_json_view')\n",
        "\n",
        "data_json = spark.sql('''\n",
        "  SELECT CASE WHEN overall<4 THEN 1\n",
        "          ELSE 0\n",
        "          END as label,\n",
        "        reviewText as text\n",
        "  FROM kindle_json_view\n",
        "  WHERE length(reviewText)>2''')\n",
        "\n",
        "data_json.groupBy('label').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Z5gMWDuz6t",
        "outputId": "3abdf0d4-3d78-4ffc-de34-83e72f8d7312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    1|11928|\n",
            "|    0|38069|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# on prend une petite partie de nos données pour faciliter l'analyse\n",
        "pos = data_json.where('label=0').sample(False, 0.05, seed=1220)\n",
        "neg = data_json.where('label=1').sample(False, 0.25, seed=1220)\n",
        "data = pos.union(neg)\n",
        "data.groupBy('label').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRR17rH0uz62",
        "outputId": "2a914bd7-5d9e-4bf4-f4cf-eac57d82416c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0| 1939|\n",
            "|    1| 3035|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "data.withColumn('longueur_avis', length('text')).groupBy('label').avg('longueur_avis').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Jh7xpzuz64",
        "outputId": "43c8a000-c2ce-4bcb-a2c8-8ce5d8faf3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------+\n",
            "|label|avg(longueur_avis)|\n",
            "+-----+------------------+\n",
            "|    0| 615.1113976276431|\n",
            "|    1|  605.902471169687|\n",
            "+-----+------------------+\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fonction pour le preprocessing"
      ],
      "metadata": {
        "id": "-_WL3EUPuz66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fonction pour preprocessing\n",
        "def clean(text):\n",
        "  import html\n",
        "  import string\n",
        "  import nltk\n",
        "  nltk.download('wordnet')\n",
        "\n",
        "  line = html.unescape(text)\n",
        "  line = line.replace(\"can't\", 'can not')\n",
        "  line = line.replace(\"n't\", \" not\")\n",
        "  # remplace ponctuations par espace\n",
        "  pad_punct = str.maketrans({key: \" {0} \".format(key) for key in string.punctuation})\n",
        "  line = line.translate(pad_punct)\n",
        "  line = line.lower()\n",
        "  line = line.split()\n",
        "  lemmatizer = nltk.WordNetLemmatizer()\n",
        "  line = [lemmatizer.lemmatize(t) for t in line]\n",
        "\n",
        "  # travail sur la négation\n",
        "  # on ajoute \"not_\" pour les mots qui suivent \"not\", ou \"no\" jusqu'à a la fin de la phrase\n",
        "  #ceci va nous aider dans notre analyse des sentiments\n",
        "  tokens = []\n",
        "  negated = False\n",
        "  for t in line:\n",
        "      if t in ['not', 'no']:\n",
        "          negated = not negated\n",
        "      elif t in string.punctuation or not t.isalpha():\n",
        "          negated = False\n",
        "      else:\n",
        "          tokens.append('not_' + t if negated else t)\n",
        "\n",
        "  invalidChars = str(string.punctuation.replace(\"_\", \"\"))\n",
        "  bi_tokens = list(nltk.bigrams(line))\n",
        "  bi_tokens = list(map('_'.join, bi_tokens))\n",
        "  bi_tokens = [i for i in bi_tokens if all(j not in invalidChars for j in i)]\n",
        "  tri_tokens = list(nltk.trigrams(line))\n",
        "  tri_tokens = list(map('_'.join, tri_tokens))\n",
        "  tri_tokens = [i for i in tri_tokens if all(j not in invalidChars for j in i)]\n",
        "  tokens = tokens + bi_tokens + tri_tokens\n",
        "\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "sZrYjXMmuz68"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# un exemple pour montrer comment la fonction fonctionne\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "example = clean(\"This is such a good book! A love story for the ages, I can't wait for the second book!!\")\n",
        "print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZylHXcUeuz6_",
        "outputId": "85c3ea4f-8042-47d7-e0e6-c5d42cb82e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'is', 'such', 'a', 'good', 'book', 'a', 'love', 'story', 'for', 'the', 'age', 'i', 'can', 'not_wait', 'not_for', 'not_the', 'not_second', 'not_book', 'this_is', 'is_such', 'such_a', 'a_good', 'good_book', 'a_love', 'love_story', 'story_for', 'for_the', 'the_age', 'i_can', 'can_not', 'not_wait', 'wait_for', 'for_the', 'the_second', 'second_book', 'this_is_such', 'is_such_a', 'such_a_good', 'a_good_book', 'a_love_story', 'love_story_for', 'story_for_the', 'for_the_age', 'i_can_not', 'can_not_wait', 'not_wait_for', 'wait_for_the', 'for_the_second', 'the_second_book']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Effectue le preprocessing sur nos données\n",
        "from pyspark.sql.functions import udf, col, size\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "clean_udf = udf(clean, ArrayType(StringType()))\n",
        "data_tokens = data.withColumn('tokens', clean_udf(col('text')))\n",
        "data_tokens.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUViC1-Cuz7B",
        "outputId": "afab05e8-b578-41d4-817a-502ed3f5c2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+\n",
            "|label|                text|              tokens|\n",
            "+-----+--------------------+--------------------+\n",
            "|    0|I am not for sure...|[i, am, not_for, ...|\n",
            "|    0|This is yet anoth...|[this, is, yet, a...|\n",
            "|    0|I almost didn't g...|[i, almost, did, ...|\n",
            "+-----+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On separe nos données en training (70%) et testing (30%)"
      ],
      "metadata": {
        "id": "SJNJ0-v6uz7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training, testing = data_tokens.randomSplit([0.7,0.3], seed=1220)\n",
        "training.groupBy('label').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ae6B2iPuz7E",
        "outputId": "15143913-7fb8-4066-e061-5bb836eb27a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0| 1351|\n",
            "|    1| 2143|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "training.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es1LbKP4uz7G",
        "outputId": "d0a1b826-4879-4e75-daac-6c53aed8dcba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[label: int, text: string, tokens: array<string>]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilisation du modele Naive Bayes"
      ],
      "metadata": {
        "id": "272lYU1puz7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "count_vec = CountVectorizer(inputCol='tokens', outputCol='c_vec', minDF=5.0)\n",
        "idf = IDF(inputCol=\"c_vec\", outputCol=\"features\")"
      ],
      "metadata": {
        "id": "S146VjH4uz7H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Modele Naive Bayes\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes()\n",
        "\n",
        "pipeline_nb = Pipeline(stages=[count_vec, idf, nb])\n",
        "\n",
        "model_nb = pipeline_nb.fit(training)\n",
        "test_nb = model_nb.transform(testing)\n",
        "test_nb.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQXpSxlXuz7I",
        "outputId": "d2add079-772a-46ad-d4e6-d0b7d1b0f878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|label|                text|              tokens|               c_vec|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|    0|\"Winter's Passage...|[winter, s, passa...|(18788,[0,1,2,4,5...|(18788,[0,1,2,4,5...|[-4913.0456154214...|[1.0,1.1067609804...|       0.0|\n",
            "|    0|&lt;mrs.featherpi...|[mr, featherpicke...|(18788,[0,1,2,3,4...|(18788,[0,1,2,3,4...|[-5638.0576384967...|[0.98151461366521...|       0.0|\n",
            "|    0|(4.5 star Top Pic...|[star, top, pick,...|(18788,[0,1,2,3,4...|(18788,[0,1,2,3,4...|[-19323.732043022...|[1.0,4.6153056670...|       0.0|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance de notre modèle Naive Bayes\n"
      ],
      "metadata": {
        "id": "zVg7Xfmouz7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC de notre modele\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "roc_nb_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\n",
        "roc_nb = roc_nb_eval.evaluate(test_nb)\n",
        "print(\"ROC de notre modele {}\".format(roc_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_PfTzXNuz7J",
        "outputId": "3701a055-cbe4-4b17-a9a9-db845fae6b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC de notre modele 0.8240863610017999\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# precision de notre modele\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "acc_nb_eval = MulticlassClassificationEvaluator(metricName='accuracy')\n",
        "acc_nb = acc_nb_eval.evaluate(test_nb)\n",
        "print(\"Precision (accuracy) de notre modele {}\".format(acc_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZq_OvLruz7K",
        "outputId": "e74f29a0-ab8b-4a4d-bfed-48573b8f04a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (accuracy) de notre modele 0.8358108108108108\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CrossValidation de notre modele Naive Bayes"
      ],
      "metadata": {
        "id": "Go5ToQLouz7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "paramGrid_nb = (ParamGridBuilder()\n",
        "                .addGrid(count_vec.minDF, [3.0, 5.0, 7.0, 10.0, 15.0])\n",
        "                .addGrid(nb.smoothing, [0.1, 0.5, 1.0])\n",
        "                .build())\n",
        "cv_nb = CrossValidator(estimator=pipeline_nb, estimatorParamMaps=paramGrid_nb, evaluator=acc_nb_eval, numFolds=5)\n",
        "cv_model_nb = cv_nb.fit(training) "
      ],
      "metadata": {
        "id": "JlcCZ09Xuz7M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_cv_nb = cv_model_nb.transform(testing)\n",
        "acc_nb_cv = acc_nb_eval.evaluate(test_cv_nb)\n",
        "print(\"Precision de notre modele avec CrossValidator: {}\".format(acc_nb_cv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ccUu44Vuz7N",
        "outputId": "e01288dd-f5dc-4a3e-eae5-57a1194faad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision de notre modele avec CrossValidator: 0.825\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prédictions sur nos propre avis:\n",
        "Pour montrer que notre modèle marche, on l'essaie sur nos propre avis : \n",
        "* un clairement positif, \n",
        "* un clairement négatif,\n",
        "* un qui mélange un peu des deux. \n"
      ],
      "metadata": {
        "id": "4n40sQ5fuz7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_1 = [\"What an excellent, excellent book! The writing style was truly excellent, and the characters were so detailed and well developed. The author surpassed themselves, can't wait for the sequel!\"]\n"
      ],
      "metadata": {
        "id": "1PSr0EZIuz7c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "review_2 = [\"One of the worst books I have ever read, one word to describe it : trash!\"]"
      ],
      "metadata": {
        "id": "UMINrJO4uz7d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "review_3 = [\"I liked the premise and most of the book. At some parts I lost a little interest because I couldn't differentiate between who was who.\"]"
      ],
      "metadata": {
        "id": "FJ5SHevXuz7d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "schema = StructType([StructField(\"text\", StringType(), True)])\n",
        "\n",
        "text = [review_1, review_2, review_3]\n",
        "review_new = spark.createDataFrame(text, schema=schema)"
      ],
      "metadata": {
        "id": "mNoW67afuz7e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing de nos données\n",
        "review_new_tokens = review_new.withColumn('tokens', clean_udf(col('text')))\n",
        "review_new_tokens.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEjyiiFiuz7f",
        "outputId": "93f26172-47a3-4e5d-b425-7b1f5adcf7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|                text|              tokens|\n",
            "+--------------------+--------------------+\n",
            "|What an excellent...|[what, an, excell...|\n",
            "|One of the worst ...|[one, of, the, wo...|\n",
            "|I liked the premi...|[i, liked, the, p...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction en utilisant nottre modele Naive Bayes\n",
        "result = cv_model_nb.transform(review_new_tokens)\n",
        "result.select('text', 'prediction').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVMRa9gOuz7g",
        "outputId": "aa66b4c0-e408-4737-b44b-d2111b624d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|                text|prediction|\n",
            "+--------------------+----------+\n",
            "|What an excellent...|       0.0|\n",
            "|One of the worst ...|       1.0|\n",
            "|I liked the premi...|       1.0|\n",
            "+--------------------+----------+\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uMAaenzIuz7i"
      },
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "name": "nlp_json",
    "notebookId": 190787089418947,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}